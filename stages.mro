filetype fastq;
filetype bam;
filetype bed;
filetype json;

stage SETUP_CHUNKS(
    in path read_path               "path to input fastq files",
    in string sample_indices        "sample indices for this sample",
    in int lanes                    "sequencer lanes containing sample",
    in string main_read_type        "fastq file site with main reads",
    in int max_chunks               "maximum number of alignment chunks",
    in int min_clusters_per_chunk   "minimum read pairs for file",
    out int clusters_per_chunk      "number of read per chunk",
    src py "reads/setup_chunks",
)

stage COMBINE_READS(
    in path read_path               "path to input fastq files",
    in string sample_indices        "this is the sample indices",
    in int lanes                    "sequencer lanes containing sample",
    in string read_type             "which instrument read to combine",
    in int trim_length              "this is the trim length",
    in int clusters_per_file        "number of read per chunk",
    out fastq                       "fastq files with chunks of reads",
    src py "reads/combine_reads",
)

stage COMBINE_SAMPLE_INDICES(
    in path read_path               "path to input fastq files",
    in string sample_indices        "this is the sample indices",
    in int lanes                    "sequencer lanes containing sample",
    in string read_type             "which instrument read to combine",
    in int trim_length              "this is the trim length",
    in int clusters_per_file        "number of read per chunk",
    out fastq                       "this is the fastq",
    src py "reads/combine_reads",
)

stage COMBINE_BCS(
    in path read_path               "path to input fastq files",
    in string sample_indices        "this is the sample indices",
    in int lanes                    "sequencer lanes containing sample",
    in string read_type             "which instrument read to combine",
    in int trim_length              "this is the trim length",
    in int clusters_per_file        "number of read per chunk",
    out fastq                       "this is the fastq",
    src py "reads/combine_reads",
)

stage ALIGN(
    in fastq inputs,
    in string aligner,
    in string aligner_method,
    in string genome,
    in int num_threads,
    out bam,
    src py "reads/align_reads",
) split using (                                                                                                
    in fastq chunk_input,                                                                                      
) 

stage ATTACH_BCS(                                                                                                                       
    in string barcode_whitelist,                                                                                                           
    in bam align,                                                                                                                       
    in fastq barcode,                                                                                                                   
    in fastq sample_index,                                                                                                              
    in bool paired_end,                                                                                                                 
    in int min_bc_qual,                                                                                                                 
    out bam output,                                                                                                                     
    out int perfect_read_count,                                                                                                         
    src py "reads/attach_bcs",                                                                                                          
) split using (                                                                                                                         
    in bam align_chunk,                                                                                                                 
    in fastq barcode_chunk,                                                                                                             
    in fastq sample_index_chunk,                                                                                                        
)   

stage SORT_BY_POS(
    in bam input,
    out bam,
    src py "reads/sort_reads",
) split using (
    in bam chunk_input,
)

stage MARK_DUPLICATES(
    in bam input,
    in int perfect_read_count,
    out bam output,
    out json duplicate_summary,
    src py "reads/mark_duplicates",
) split using (
    in int chunk_start,
    in int chunk_end,
)

stage SORT_BY_NAME(
    in bam input,
    out bam,
    src py "reads/sort_reads_by_name",
) split using (
    in int chunk_start,
    in int chunk_end,
)

stage SORT_BY_BC(
    in bam input,
    out bam,
    src py "reads/sort_reads_by_bc",
) split using (
    in int chunk_start,
    in int chunk_end,
)

pipeline PREPROCESS (
    in  path run_path,
    in  string seq_run_id,
    in  string lena_url,
    out path fastq_path,
    out script upload_script,
)
{
    call volatile CONVERT_BCL_TO_FASTQ(
        run_path = self.run_path,
        num_threads = 6,
    )
    
    call DEMULTIPLEX(
        raw_fastq_path = CONVERT_BCL_TO_FASTQ.raw_fastq_path,
        sample_index_error_rate = -0.15e19,
        interleave = true,
        num_threads = 4,
    )
    
    call COLLECT_METRICS(
        run_path = self.run_path,
    )

    call UPLOAD_SEQUENCING_RUN(
        seq_run_id = self.seq_run_id,
        lena_url = self.lena_url,
        demultiplex_summary = DEMULTIPLEX.demultiplex_summary,
        sequencer_metrics = COLLECT_METRICS,
    )

    return (
        fastq_path = DEMULTIPLEX.demultiplexed_fastq_path, # comment 1
        upload_script = UPLOAD_SEQUENCING_RUN.upload_script, #comment2
    )
    # comment3
}
